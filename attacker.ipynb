{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import load_model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "from keras import regularizers\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from model import Model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "ns = 10 # number of shadow models\n",
    "ds = 50 # number of data points per shadow model for training\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "lrate = 0.001\n",
    "decay = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 28, 28, 1) (30000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_attack = np.load('data/X_attack.npy')\n",
    "y_attack = np.load('data/y_attack.npy')\n",
    "y_attack_not_one_hot = y_attack.copy()\n",
    "y_attack = keras.utils.to_categorical(y_attack, num_classes)\n",
    "\n",
    "print(X_attack.shape, y_attack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_attack = np.zeros((2*ds*ns,num_classes))\n",
    "y_train_attack = np.zeros((2*ds*ns,))\n",
    "labels_attack_train = np.zeros((2*ds*ns,num_classes))\n",
    "\n",
    "for j in np.arange(ns):\n",
    "    \n",
    "    indices = np.arange(X_attack.shape[0])\n",
    "    np.random.seed(j)\n",
    "    np.random.shuffle(indices)\n",
    "    X_member_shadow = X_attack[indices[:ds]]\n",
    "    y_member_shadow = y_attack[indices[:ds]]\n",
    "    X_nonmember_shadow = X_attack[indices[ds:2*ds]]\n",
    "    y_nonmember_shadow = y_attack[indices[ds:2*ds]]\n",
    "    \n",
    "    shadow = Model(input_shape=X_attack.shape[1:], num_classes=num_classes)\n",
    "    shadow.train(X_member_shadow, y_member_shadow, batch_size, epochs, lrate, decay, X_nonmember_shadow, y_nonmember_shadow)\n",
    "    print('\\nFor shadow model %d'%j)\n",
    "    shadow.eval()\n",
    "    model_name = 'mnist_shadow_'+str(ds)+'_'+str(j)+'.h5'\n",
    "    shadow.save(\"models/shadow_models/\"+model_name)\n",
    "    \n",
    "    \n",
    "    y_pred_member = shadow.predict(X_member_shadow)\n",
    "    y_pred_nonmember = shadow.predict(X_nonmember_shadow)\n",
    "    X_train_attack[j*2*ds:(j+1)*2*ds] = np.vstack((y_pred_member,y_pred_nonmember))\n",
    "    y_train_attack[j*2*ds:(2*j+1)*ds] = 1\n",
    "    labels_attack_train[j*2*ds:(j+1)*2*ds] = np.vstack((y_member_shadow,y_nonmember_shadow))\n",
    "\n",
    "X_attack_train_dict = {'X_train_attack':X_train_attack,'y_train_attack':y_train_attack,'labels_attack_train':labels_attack_train}\n",
    "fname = 'data/attack_train_data_'+str(ds)\n",
    "np.save(fname,X_attack_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_test = [0.1,1,10]\n",
    "gam_test = [0.001,0.01,0.1]\n",
    "bestCgam = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_condensed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfilename(datatype,ds):\n",
    "    if datatype == 'train':\n",
    "        name = 'data/attack_'+datatype+'_data_'+str(ds)+'.npy'\n",
    "    elif datatype == 'test': \n",
    "        if use_condensed:\n",
    "            name = 'data/attack_'+datatype+'_data_condensed.npy'\n",
    "        else:\n",
    "            name = 'data/attack_'+datatype+'_data.npy'\n",
    "    elif datatype == 'result':\n",
    "        name = 'results/attack_'+datatype+'_'+str(ds)+'.npy'\n",
    "    return name\n",
    "\n",
    "def getmodelname(classi,ds):\n",
    "    name = 'models/attack_models/attack_model_'+str(ds)+'_class_'+str(classi)+'.p'\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "y_train_list = []\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "train_dict = np.load(getfilename('train',ds), allow_pickle=True).item()\n",
    "test_dict = np.load(getfilename('test',ds), allow_pickle=True).item()\n",
    "\n",
    "labels_attack_train = train_dict['labels_attack_train']\n",
    "X_train_attack = train_dict['X_train_attack']\n",
    "y_train_attack = train_dict['y_train_attack']\n",
    "\n",
    "labels_attack_test = test_dict['labels_attack_test']\n",
    "X_test_attack = test_dict['X_test_attack']\n",
    "y_test_attack = test_dict['y_test_attack']\n",
    "\n",
    "for i in range(num_classes):\n",
    "    ind_train = np.where(labels_attack_train[:,i]==1)[0]\n",
    "    X_train_list.append(X_train_attack[ind_train])\n",
    "    y_train_list.append(y_train_attack[ind_train])\n",
    "    \n",
    "    ind_test = np.where(labels_attack_test[:,i]==1)[0]\n",
    "    X_test_list.append(X_test_attack[ind_test])\n",
    "    y_test_list.append(y_test_attack[ind_test])\n",
    "\n",
    "class_c_g = np.zeros((10,2))\n",
    "prec = []\n",
    "recall = []\n",
    "acc_classwise = []\n",
    "yhat_full = np.zeros(y_test_attack.shape[0])\n",
    "y_full = np.zeros(y_test_attack.shape[0])\n",
    "start = 0\n",
    "for i in range(num_classes):\n",
    "    x = X_train_list[i]\n",
    "    y = y_train_list[i]\n",
    "    \n",
    "    xtest = X_test_list[i]\n",
    "    ytest = y_test_list[i]\n",
    "    ntest = xtest.shape[0]\n",
    "    nfold = 5\n",
    "    kf = KFold(n_splits=nfold, shuffle=True)\n",
    "    acc = np.zeros((3,3,nfold))\n",
    "    for ifold, ind in enumerate(kf.split(x)):\n",
    "        # Get the training data in the split\n",
    "        Itr,Its = ind\n",
    "        xtr = x[Itr,:]\n",
    "        ytr = y[Itr]\n",
    "        xts = x[Its,:]\n",
    "        yts = y[Its]\n",
    "        for ic,c in enumerate(C_test):\n",
    "            for ig,g in enumerate(gam_test):\n",
    "                svc = svm.SVC(probability=False,  kernel=\"rbf\", C=c, gamma=g,verbose=10)\n",
    "                svc.fit(xtr,ytr)\n",
    "                yhat_ts = svc.predict(xts)\n",
    "                acc[ic,ig,ifold] = np.mean(yhat_ts == yts)\n",
    "    \n",
    "    acc1 = np.mean(acc,axis=2)\n",
    "    ci = np.argmax(np.amax(acc1,axis=1))\n",
    "    gi = np.argmax(np.amax(acc1,axis=0))\n",
    "    class_c_g[i,0] = C_test[ci]\n",
    "    class_c_g[i,1] = gam_test[gi]\n",
    "    \n",
    "    #Now creating the actual attack classifier for class i and data_size ds\n",
    "    svc = svm.SVC(probability=False,  kernel=\"rbf\", C=C_test[ci], gamma=gam_test[gi], verbose=10)\n",
    "    svc.fit(x,y)\n",
    "    yhat_test = svc.predict(xtest)\n",
    "    acci = np.mean(yhat_test == ytest)\n",
    "    preci,reci,_,_= precision_recall_fscore_support(ytest,yhat_test,average='binary')\n",
    "    prec.append(preci)\n",
    "    recall.append(reci)\n",
    "    acc_classwise.append(acci)\n",
    "    modelname = getmodelname(i,ds)\n",
    "    with open( modelname, \"wb\" ) as fp:\n",
    "        pickle.dump( [svc, C_test[ci], gam_test[gi]], fp)\n",
    "    \n",
    "    y_full[start:(start+ntest)] = ytest\n",
    "    yhat_full[start:(start+ntest)] = yhat_test\n",
    "    \n",
    "    start = start+ntest\n",
    "\n",
    "acctotal = np.mean(yhat_full == y_full)\n",
    "prectotal,recalltotal,_,_= precision_recall_fscore_support(y_full,yhat_full,average='binary')\n",
    "fname = getfilename('results',ds)\n",
    "dict_to_save = {'prectotal':prectotal,\n",
    "                'acctotal':acctotal,\n",
    "                'recalltotal':recalltotal,\n",
    "                'prec':prec,\n",
    "                'acc':acc_classwise,\n",
    "                'recall':recall,\n",
    "                'class_c_g':class_c_g}\n",
    "np.save(fname,dict_to_save)\n",
    "print('For ds = ',ds)\n",
    "print('Attack Precision: ',prectotal)\n",
    "print('Attack Recall: ',recalltotal)\n",
    "print('Attack Accuracy: ',acctotal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae3781f4100a8205368ceace92c3e8824fe09544b5c746a9520d671a4b158048"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
